if( settings[[ "rt_penalty" ]] == "d600" ) {
penalty = correct_mean + 600;
} else {
penalty = correct_mean + 2 * correct_sd;
}
if( "penalty" %in% settings[[ "aux_report" ]] ) {
result[[ paste( "penalty", comp_level, sep = "." ) ]] = penalty;
}
# Apply penalty to each resp_penalty
for( resp_penalty in settings[[ "resp_penalty" ]] ) {
if( resp_penalty == "NA" ) {
resp_to_penalize = is.na( ds_subset[ ,resp_var ] );
} else {
resp_to_penalize = ds_subset[ ,resp_var ] == resp_penalty;
}
g_resp_to_penalize <<- resp_to_penalize;
# print( "penalize before" );
if( length( resp_to_penalize ) > 0 && !is.na( resp_to_penalize ) ) {
ds_subset[
ds_subset[ ,comp_var ] == comp_level &
resp_to_penalize,
rt_var
] = penalty;
}
# print( "penalize after" );
}
# Calculate mean adjusted for penalty
# print( "adjusted before" );
adjusted_means[[ comp_level ]] = mean(
ds_subset[
ds_subset[ ,comp_var ] == comp_level,
rt_var
], na.rm = T
);
# print( "adjusted after" );
if( "adjusted_mean" %in% settings[[ "aux_report" ]] ) {
result[[ paste( "adjusted_mean", comp_level, sep = "." ) ]] = adjusted_means[[ comp_level ]];
}
}
# ***********
# *** Calculate inclusive SD and dscore
inclusive_sd = sd( ds_subset[ ,rt_var ], na.rm = T );
if( "inclusive_sd" %in% settings[[ "aux_report" ]] ) {
result[[ "inclusive_sd" ]] = inclusive_sd;
}
dscore = (
adjusted_means[[ settings[[ "comp_levels"]][2] ]] -
adjusted_means[[ settings[[ "comp_levels"]][1] ]]
) / inclusive_sd;
result[[ "dscore" ]] = dscore;
return( result );
}
# Calculates two d-scores; one on each split halve of ds_subset
one_dscore_split = function( result, ds_subset, settings = list() ) {
comp_var = settings[[ "comp_var" ]];
ds_subset[ ,"split" ] = NA;
for( comp_level in settings[[ "comp_levels" ]] ) {
n_split = sum( ds_subset[ ,comp_var ] == comp_level );
ds_subset[ ds_subset[ ,comp_var ] == comp_level, "split" ] = sample(
rep( 1:2, ceiling( n_split / 2 ) )
)[ 1 : n_split ];
}
for( split_i in 1:2 ) {
ds_subset_split = ds_subset[ ds_subset[ ,"split" ] == split_i, ];
result_split = one_dscore( result, ds_subset_split, settings );
result[[ paste( "dscore", split_i, sep = "_" ) ]] = result_split[[ "dscore" ]];
}
return( result );
}
# Calculates two d-scores; one on first halve, one on second halve of ds_subset
dscore_first_second = function( result, ds_subset, settings = list() ) {
# g_ds_subset <<- ds_subset;
comp_var = settings[[ "comp_var" ]];
ds_subset[ ,"split" ] = NA;
for( comp_level in settings[[ "comp_levels" ]] ) {
n_split = sum( ds_subset[ ,comp_var ] == comp_level );
n_split_1 = ceiling( n_split / 2 );
n_split_2 = n_split - n_split_1;
ds_subset[ ds_subset[ ,comp_var ] == comp_level, "split" ] = c(
rep( 1, n_split_1 ),
rep( 2, n_split_2 )
);
}
for( split_i in 1:2 ) {
ds_subset_split = ds_subset[ ds_subset[ ,"split" ] == split_i, ];
result_split = one_dscore( result, ds_subset_split, settings );
result[[ paste( "dscore", split_i, sep = "_" ) ]] = result_split[[ "dscore" ]];
}
return( result );
}
# *****************************************
# *** End of inner function definitions ***
# *****************************************
# Calculate dscores for multiple runs of a task as identified by "run_var"
# Select only compatible and incompatible from ds
ds = ds[
ds[ ,settings[[ "comp_var" ]] ] == settings[[ "comp_levels" ]][1] |
ds[ ,settings[[ "comp_var" ]] ] == settings[[ "comp_levels" ]][2],
];
# splithalves < 1? calculate dscore over full data,
# else calculate splithalve correlation splithalves times
if( splithalves < 1 ) {
# *** No split_halve, calculate and return a single (set of) d-scores
# What dscore function to use
dscore_function = switch(
what,
# Calculate one score over full task data
all = one_dscore,
# Calculate two scores: one for first and one for second halve of task
first_second = dscore_first_second
);
return( niceBy(
ds,
c( settings[[ "run_var" ]] ),
dscore_function,
settings = settings,
verbose = verbose,
...
) );
} else {
# *** Else, calculate splithalves split_halve times
# Correlations to average
cors = c();
for( split_halve_i in 1 : splithalves ) {
# Run split_halve
split_result = niceBy(
ds,
c( settings[[ "run_var" ]] ),
one_dscore_split,
settings = settings,
verbose = verbose,
...
);
# DEBUG
g_split_result <<- split_result;
# Calculate correlation, add to list
split_cor = cor(
suppressWarnings( as.numeric( split_result[ ,"dscore_1" ] ) ),
suppressWarnings( as.numeric( split_result[ ,"dscore_2" ] ) ),
use = "pairwise.complete.obs"
);
cors = c( cors, split_cor );
if( verbose ) {
print( paste(
Sys.time(), ", dscores, split ",
split_halve_i, "/", splithalves, ", r = ", split_cor,
sep = ""
) );
}
}
# DEBUG
# g_cors <<- cors;
# Return mean of correlations
return( mean( cors ) );
}
}
applyAggregation = function( result, ds_subset, settings ) {
# Calculate individualResult by applying settings[["aggregation_factor_function"]] to each set of RTs as
# selected by unique combinations of settings[["aggregation_factors"]]
individualResult = niceBy(
ds_subset,
settings[["aggregation_factors"]],
function( result, ds_subset ) {
result[["score"]] = settings[["aggregation_factor_function"]](
ds_subset[,settings[["rt_var"]]]
);
return(result);
}
);
# Mage wide and convert to numeric
if("dummy_id" %in% names(individualResult)) {
stop("Column named 'dummy_id' found in aggregation function output; this column name cannot be used")
}
individualResult[,"dummy_id"] = 1;
individualResult[,"score"] = as.numeric(as.character(individualResult[,"score"]));
wide = makeWide(
individualResult,
c("dummy_id"),
settings[["aggregation_factors"]]
);
# Apply aggregation_run_function on scores
result[["score"]] = settings[["aggregation_run_function"]](wide);
# If aux_report features "factor_scores" report aggregation_factor_function output
if("factor_scores" %in% settings[["aux_report"]]) {
wide = data.frame.dropVar(wide,"dummy_id");
for(i in names(wide)) {
result[[i]] = wide[1,i];
}
}
return(result)
}
oneScore = function( result, ds_subset, settings ) {
resp_var = settings[[ "resp_var" ]];
rt_var   = settings[[ "rt_var"   ]];
# Drop and report responses and rt's
ds_subset[ ,rt_var ] = suppressWarnings( as.numeric( ds_subset[ ,rt_var ] ) );
temp = dropAndReport( result, ds_subset, settings );
result = temp[["result"]];
ds_subset = temp[["ds_subset"]];
result = applyAggregation( result, ds_subset, settings );
return(result);
}
# Calculates two d-scores; one on each split halve of ds_subset
oneScoreSplit = function( result, ds_subset, settings, verbose = F ) {
ds_debug <<- ds_subset;
ds_subset = niceBy(
ds_subset,
settings[["aggregation_factors"]],
function( result, ds_subset ) {
debug_ds<<-ds_subset;
ds_subset[ ,"split" ] = sample(
rep( 1:2, ceiling( nrow(ds_subset) / 2 ) )
)[ 1 : nrow(ds_subset) ];
return(ds_subset);
},
result_type = "data.frame_to_data.frame",
verbose = verbose
);
for( split_i in 1:2 ) {
ds_subset_split = ds_subset[ ds_subset[ ,"split" ] == split_i, ];
result_split = oneScore( result, ds_subset_split, settings );
result[[ paste( "score", split_i, sep = "_" ) ]] = result_split[[ "score" ]];
}
return(result);
}
#' Calculates scores from trial data using the 'aggregation' approach
#'
#' @export
#' @param ds          (data.frame) Trial data.
#' @param settings    (list) D-score calculation settings.
#' @param splithalves (integer) If 0, return a single set of d-scores, if > 0, return randomized split-halve reliability averaged over splithalves iterations.
#' @param verbose     (logical) If TRUE, then print debug output.
#' @param ...         Remaining arguments are passed to an internal scoring function. Not used at the moment.
#' @return (data.frame) Calculated d-scores.
#'
#' @details
#' The table below shows an overview of elements in settings and their meaning.
#' \tabular{lllll}{
#'   \strong{Name} \tab \strong{Type} \tab \strong{Required?} \tab  \strong{Example Value} \tab \strong{Description} \cr
#'   aggregation_factors \tab character \tab Yes \tab \code{} \tab Apply aggregation_factor_function to each subset of ds formed by unique combinations of values for these variables \cr
#'   aggregation_factor_function \tab character \tab Yes \tab \code{} \tab Function applied to calculate aggregated scores (e.g. 'median rt for correct responses') \cr
#'   aggregation_run_function \tab character \tab Yes \tab \code{} \tab Function applied to output of aggregation_factor_function (e.g. difference of medians between red and blue conditions) \cr
#' }
#' @seealso \code{\link[sandra]{dropAndReport}} for additional settings that can be used for
#' dropping and reporting responses and response times before scores are calculated.
#'
#' @family SANDRA
#' @examples
#' See: SANDRA/framework_demos/scripts/0.t.2 Calculate Scores.R
#' @export
calculateAggregation = function( ds, settings, splithalves = 0, verbose = F, ... ) {
# splithalves < 1? calculate scores over full data,
# else calculate splithalve correlation splithalves times
if( splithalves < 1 ) {
return( niceBy(
ds,
c( settings[[ "run_var" ]] ),
oneScore,
verbose = verbose,
settings = settings,
...
) );
} else {
# Correlations to average
cors = c();
for( split_halve_i in 1 : splithalves ) {
# Run split_halve
split_result = niceBy(
ds,
c( settings[[ "run_var" ]] ),
oneScoreSplit,
verbose = verbose,
settings = settings,
...
);
# DEBUG
g_split_result <<- split_result;
# Calculate correlation, add to list
split_cor = cor(
suppressWarnings( as.numeric( as.character( split_result[ ,"score_1" ] ) ) ),
suppressWarnings( as.numeric( as.character( split_result[ ,"score_2" ] ) ) ),
use = "pairwise.complete.obs"
);
cors = c( cors, split_cor );
if( verbose ) {
print( paste(
Sys.time(), ", dscores, split ",
split_halve_i, "/", splithalves, ", r = ", split_cor,
sep = ""
) );
}
}
# DEBUG
g_cors <<- cors;
# Return mean of correlations
return( mean( cors ) );
}
}
#' Calculates scores from trial data
#'
#' @export
#' @param ds          (data.frame) Trial data.
#' @param settings    (list) D-score calculation settings.
#' @param what        (character) If "dscore", calculate d-scores, else, use the 'aggregation' approach (like for difference of medians etc.)
#' @param splithalves (integer) If 0, return a single set of d-scores, if > 0, return randomized split-halve reliability averaged over splithalves iterations.
#' @param verbose     (logical) If TRUE, then print debug output.
#' @param ...         Remaining arguments are passed to an internal scoring function. Not used at the moment.
#' @return (data.frame) Calculated d-scores.
#'
#' @details
#' The table below shows an overview of elements in settings and their meaning.
#' \tabular{lllll}{
#'   \strong{Name} \tab \strong{Type} \tab \strong{Required?} \tab  \strong{Example Value} \tab \strong{Description} \cr
#'   run_var \tab character \tab Yes \tab \code{"set_id"} \tab Variable in trialdata that identifies a participation. \cr
#'   resp_var \tab character \tab Yes \tab \code{"response"} \tab Variable in trialdata that identifies responses (being correct, incorrect, etc.). \cr
#'   rt_var \tab character \tab Yes \tab \code{"rt"} \tab Variable in trialdata that identifies response times. \cr
#' }
#' @seealso \code{\link[sandra]{dropAndReport}} for additional settings that can be used for
#' dropping and reporting responses and response times before scores are calculated.
#' @seealso \code{\link[sandra]{calculateDScores}} for additional settings that can be used for
#' d-score calculations
#' @seealso \code{\link[sandra]{calculateAggregation}} for additional settings that can be used for
#' the 'aggregation' approach to scoring
#'
#' @family SANDRA
#' @examples
#' See: SANDRA/framework_demos/scripts/0.t.2 Calculate Scores.R
#' @export
calculateScores = function( ds, settings, type, splithalves = 0, verbose = F, ... ) {
if( type == "dscore" ) {
return( calculateDScores(
ds, settings, splithalves, verbose, ...
) );
} else {
return( calculateAggregation(
ds, settings, splithalves, verbose, ...
) );
}
}
# Copyright (c) 2015 Thomas Pronk <pronkthomas@gmail.com>
# All rights reserved. No warranty, explicit or implicit, provided.
#' Wrapper for R's native by function
#'
#' Calls the function 'aggregation' for each unique combination of values of the the columns factors in the dataframe ds.
#' The aggregation function is called with two arguments: (1) (list) result list to add aggregation output to, and (2) (data.frame) subset of data selected by this combination of values for factors
#' If niceBy is set to return a data frame, then names of variables in this data frame
#' are are drawn from the names of the elements in the list returned by the aggregation
#' funtion. The aggregation function can return a list of scalars if each call to
#' aggregation produces one row of output, or it can return a list of list of scalars
#' if each call produces one or more rows of output.
#'
#' @export
#' @param ds              (data.frame) Dataset to aggregate
#' @param factors         (vector) Columns in dataset that serve as factors
#' @param aggregation     (function) Aggregation
#' @param result_type     (character) Three possible values: "data.frame", "vector", any other is interpreted as "list
#' @param verbose         (logical) If TRUE, then print debug output
#' @param ...             Additional arguments passed to aggregation function
#' @return (mixed) Aggregation result
#' @family SANDRA
niceBy = function(
ds,
factors,
aggregation,
result_type = "list_to_data.frame",
verbose = F,
...
) {
# *** Construct factors
if( verbose ) { print( paste( Sys.time(), ", niceBy, construct factors", sep = "" ) ); }
indices = list();
for( f in factors ) {
indices[[ length( indices ) + 1 ]] = ds[ ,f ];
}
# *** Create a list with all the subsets
if( verbose ) { print( paste( Sys.time(), ", niceBy, create subsets", sep = "" ) ); }
ds_list = by(
ds,
indices,
function( subset ) {
return( subset );
}
);
# Remove NULL values in subsets
ds_list = ds_list[ which( !unlist( lapply( ds_list, is.null ) ) ) ];
# *** Apply aggregation to each element of ds_list
if( verbose ) { print( paste( Sys.time(), ", niceBy, apply aggregations", sep = "" ) ); }
result_raw = lapply(
ds_list,
function( subset ) {
# Fill result with levels of each factor
result = list();
for( f in factors ) {
result[[ f ]] = subset[ 1, f ];
}
# Call aggregation with result and subset argument
result = aggregation(
result,
subset,
...
);
return( result );
}
);
if( verbose ) { print( paste( Sys.time(), ", niceBy, aggregations done", sep = "" ) ); }
if( result_type == "list_to_data.frame" ) {
# list of lists to data.frame
if( length( result_raw[[1]][[1]] ) > 1 ) {
# List of lists
result_names = names( result_raw[[1]][[1]] );
ncol = length( result_raw[[1]][[1]] );
} else {
result_names = names( result_raw[[1]] );
ncol = length( result_raw[[1]] );
}
# Sort names in list elements according to first element
sorted_result_raw = list();
for( i in 1 : length( result_raw ) ) {
sorted_result_raw[[i]] = result_raw[[i]][result_names];
}
result = data.frame( matrix(
unlist( sorted_result_raw ),
ncol = ncol,
byrow = T
) );
names( result ) = result_names;
# Get names from first element of result_raw (if it is a list),
# or from first element of first element of list (if it is a list of lists)
#     if( length( result_raw[[1]][[1]] ) > 1 ) {
#       names( result ) = names( result_raw[[1]][[1]] );
#     } else {
#       names( result ) = names( result_raw[[1]] );
#     }
} else if( result_type == "data.frame_to_data.frame" ) {
# data.frame to data.frame
result = result_raw[[1]];
if(length(result_raw) > 1) {
for(i in 2:length(result_raw)) {
result = rbind(result, result_raw[[i]]);
}
}
} else if( result_type == "vector" ) {
# vector
result = unlist( result_raw );
} else {
# list
result = result_raw;
}
return( result );
}
ds = io$readData( "tests.trialdata.aat.csv", original = T );
settings = list(
run_var = "set_id",
resp_var = "response",
rt_var = "rt",
fast_drop = 200,
slow_drop = 2000,
fast_report = 200,
slow_report = 2000,
resp_report = c(1),
resp_drop = c(2,3,4,NA),
aux_report = c("factor_scores"),
aggregation_factors = c( "appr", "cat" ),
aggregation_factor_function = function( rts ) {
return( median( rts ) )
},
aggregation_run_function = function( wide ) {
print(wide);
score =
( wide["score.test.no"] - wide["score.test.yes"] ) -
( wide["score.control.no"] - wide["score.control.yes"] );
return(score);
}
);
calculatedScores = calculateScores(
type = "aggregation",
ds,
settings
);
io$writeData( "tests.medians.aat.csv", calculatedScores );
# Compare scores generated by calculateScores with those calculated manually
correctScores = io$readData( "tests.medians.aat.csv", original = T );
# Matrix with TRUE  for each matching score, and FALSE if not
matches = data.frame.new();
for( i in 1 : nrow(correctScores) ) {
correctRow = correctScores[i,];
calculatedRow = calculatedScores[calculatedScores[,"set_id"] == correctRow[,"set_id"],];
for( j in names( correctRow ) ) {
if( !(is.na(correctRow[j]) && is.na(calculatedRow[j])) ) {
if(
(is.na(correctRow[j]) && !is.na(calculatedRow[j])) ||
(!is.na(correctRow[j]) && is.na(calculatedRow[j])) ||
correctRow[j] != calculatedRow[j]
) {
print( paste(
"Mismatch between correct calculated in",
"set_id", correctRow[,"set_id"],
"column", j,
"correct =", correctRow[,j],
"calculated =", calculatedRow[,j]
) );
matches[i,j] = FALSE;
} else {
matches[i,j] = TRUE;
}
} else {
matches[i,j] = TRUE;
}
}
matches[i,"set_id"] = correctRow[,"set_id"];
}
io$writeData( "tests.medians.matches.aat.csv", matches );
