# Load sandra R scripts from a local directory
pathSandra = "D:/wamp/www/sandra/trunk/src/R";
library( "rjson" )
library( "lubridate" )
library( "tcltk" )
modules = dir( pathSandra, pattern = "[.]R$" );
for( m in modules ) {
source( paste( pathSandra, m, sep = "/" ) );
}
ds = io$readData( "1-AAT_lotus.aat.trialdata.csv" );
metadata = io$readData( "1-AAT_lotus.metadata.csv" );
# Only select assess blocks
ds = ds[ ds[ ,"type" ] == "assess", ];
# D-Score
settings = list(
run_var      = "set_id",
resp_var     = "response",
rt_var       = "rt",
comp_var     = "appr",
comp_levels  = c( "yes", "no" ), # Bias calculated towards first element
fast_drop    = 300,
fast_report  = 300,
resp_drop    = c( "NA", 0, 3, 4 ),
resp_report  = c( 1 ),
resp_correct = 1,
resp_penalty = c( 2 ),
rt_penalty   = "2sd",
aux_report   = c(
# For each compatible and incompatible block
"correct_n", "correct_mean", "correct_sd", "penalty", "adjusted_mean",
# Across compatible and incompatible
"inclusive_sd",
# Across task
"task_n"
)
);
# Scores per level of cat
scores = list();
for( catCur in c( "test", "control" ) ) {
dsCur = ds[ ds[ ,"cat" ] == catCur, ];
scores[[ catCur ]] = calculateDScores(
dsCur,
settings
);
scores[[ catCur ]] = data.frame.affixNames(
scores[[ catCur ]],
postfix = catCur,
not = c( "set_id" )
);
}
# Merge test and control
scores = niceMerge(
scores[[ "test" ]],
scores[[ "control" ]],
c( "set_id" )
);
# Merge with metadata
scores = leftMerge(
scores,
metadata,
c( "set_id" )
);
io$writeData(
"1-AAT_lotus.dscores.csv",
scores
);
# Load sandra R scripts from a local directory
pathSandra = "D:/wamp/www/sandra/trunk/src/R";
library( "rjson" )
library( "lubridate" )
library( "tcltk" )
modules = dir( pathSandra, pattern = "[.]R$" );
for( m in modules ) {
source( paste( pathSandra, m, sep = "/" ) );
}
io  = FrameworkFileIO( "D:/wamp/www/mirte/Studies/2015 - SANDRA Analyses/analysis" );
ds = io$readData( "1-AAT_lotus.aat.trialdata.csv" );
metadata = io$readData( "1-AAT_lotus.metadata.csv" );
# Only select assess blocks
ds = ds[ ds[ ,"type" ] == "assess", ];
# D-Score
settings = list(
run_var      = "set_id",
resp_var     = "response",
rt_var       = "rt",
comp_var     = "appr",
comp_levels  = c( "yes", "no" ), # Bias calculated towards first element
fast_drop    = 300,
fast_report  = 300,
resp_drop    = c( "NA", 0, 3, 4 ),
resp_report  = c( 1 ),
resp_correct = 1,
resp_penalty = c( 2 ),
rt_penalty   = "2sd",
aux_report   = c(
# For each compatible and incompatible block
"correct_n", "correct_mean", "correct_sd", "penalty", "adjusted_mean",
# Across compatible and incompatible
"inclusive_sd",
# Across task
"task_n"
)
);
# Scores per level of cat
scores = list();
for( catCur in c( "test", "control" ) ) {
dsCur = ds[ ds[ ,"cat" ] == catCur, ];
scores[[ catCur ]] = calculateDScores(
dsCur,
settings
);
scores[[ catCur ]] = data.frame.affixNames(
scores[[ catCur ]],
postfix = catCur,
not = c( "set_id" )
);
}
# Merge test and control
scores = niceMerge(
scores[[ "test" ]],
scores[[ "control" ]],
c( "set_id" )
);
# Merge with metadata
scores = leftMerge(
scores,
metadata,
c( "set_id" )
);
io$writeData(
"1-AAT_lotus.dscores.csv",
scores
);
NA > 20
!( NA > 20 )
if( NA > 20 ) { print( "test"); }
ds = io$readData( "1-AAT_lotus.aat.trialdata.csv" );
metadata = io$readData( "1-AAT_lotus.metadata.csv" );
# Only select assess blocks
ds = ds[ ds[ ,"type" ] == "assess", ];
# D-Score
settings = list(
run_var      = "set_id",
resp_var     = "response",
rt_var       = "rt",
comp_var     = "appr",
comp_levels  = c( "yes", "no" ), # Bias calculated towards first element
fast_drop    = 300,
fast_report  = 300,
resp_drop    = c( "NA", 0, 3, 4 ),
resp_report  = c( 1 ),
resp_correct = 1,
resp_penalty = c( 2 ),
rt_penalty   = "2sd",
aux_report   = c(
# For each compatible and incompatible block
"correct_n", "correct_mean", "correct_sd", "penalty", "adjusted_mean",
# Across compatible and incompatible
"inclusive_sd",
# Across task
"task_n"
)
);
# Scores per level of cat
scores = list();
for( catCur in c( "test", "control" ) ) {
dsCur = ds[ ds[ ,"cat" ] == catCur, ];
scores[[ catCur ]] = calculateDScores(
dsCur,
settings
);
scores[[ catCur ]] = data.frame.affixNames(
scores[[ catCur ]],
postfix = catCur,
not = c( "set_id" )
);
}
# Merge test and control
scores = niceMerge(
scores[[ "test" ]],
scores[[ "control" ]],
c( "set_id" )
);
# Merge with metadata
scores = leftMerge(
scores,
metadata,
c( "set_id" )
);
io$writeData(
"1-AAT_lotus.dscores.csv",
scores
);
ds = io$readData( "1-AAT_lotus.aat.trialdata.csv" );
metadata = io$readData( "1-AAT_lotus.metadata.csv" );
# Only select assess blocks
ds = ds[ ds[ ,"type" ] == "assess", ];
# D-Score
settings = list(
run_var      = "set_id",
resp_var     = "response",
rt_var       = "rt",
comp_var     = "appr",
comp_levels  = c( "yes", "no" ), # Bias calculated towards first element
fast_drop    = 300,
fast_report  = 300,
resp_drop    = c( "NA", 0, 3, 4 ),
resp_report  = c( 1 ),
resp_correct = 1,
resp_penalty = c( 2 ),
rt_penalty   = "2sd",
aux_report   = c(
# For each compatible and incompatible block
"correct_n", "correct_mean", "correct_sd", "penalty", "adjusted_mean",
# Across compatible and incompatible
"inclusive_sd",
# Across task
"task_n"
)
);
# Scores per level of cat
scores = list();
for( catCur in c( "test", "control" ) ) {
dsCur = ds[ ds[ ,"cat" ] == catCur, ];
scores[[ catCur ]] = calculateDScores(
dsCur,
settings
);
scores[[ catCur ]] = data.frame.affixNames(
scores[[ catCur ]],
postfix = catCur,
not = c( "set_id" )
);
}
# Merge test and control
scores = niceMerge(
scores[[ "test" ]],
scores[[ "control" ]],
c( "set_id" )
);
# Merge with metadata
scores = leftMerge(
scores,
metadata,
c( "set_id" )
);
io$writeData(
"1-AAT_lotus.dscores.csv",
scores
);
